{
  "name": "-tokenization",
  "version": "1.0.0",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC",
  "description": "",
  "dependencies": {
    "@langchain/community": "^0.3.56",
    "@langchain/core": "^0.3.77",
    "@langchain/openai": "^0.6.13",
    "@langchain/qdrant": "^0.1.3",
    "axios": "^1.12.2",
    "dotenv": "^16.4.5",
    "js-tiktoken": "^1.0.21",
    "openai": "^4.62.1",
    "pdf-parse": "^1.1.1"
  }
}
